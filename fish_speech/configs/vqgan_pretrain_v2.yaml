defaults:
  - base
  - _self_

project: vqgan_pretrain_v2
ckpt_path: checkpoints/hifigan-base-comb-mix-lb-020/step_001200000_weights_only.ckpt
resume_weights_only: true

# Lightning Trainer
trainer:
  accelerator: gpu
  devices: auto
  strategy: ddp_find_unused_parameters_true
  precision: 32
  max_steps: 1_000_000
  val_check_interval: 5000

sample_rate: 44100
hop_length: 512
num_mels: 160
n_fft: 2048
win_length: 2048
segment_size: 256

# Dataset Configuration
train_dataset:
  _target_: fish_speech.datasets.vqgan.MixDatast
  datasets:
    high-quality-441:
      prob: 0.5
      dataset:
        _target_: fish_speech.datasets.vqgan.VQGANDataset
        filelist: data/vocoder_data_441/vq_train_filelist.txt
        sample_rate: ${sample_rate}
        hop_length: ${hop_length}
        slice_frames: ${segment_size}
    
    common-voice:
      prob: 0.5
      dataset:
        _target_: fish_speech.datasets.vqgan.VQGANDataset
        filelist: data/cv-corpus-16.0-2023-12-06/vq_train_filelist.txt
        sample_rate: ${sample_rate}
        hop_length: ${hop_length}
        slice_frames: ${segment_size}

val_dataset:
  _target_: fish_speech.datasets.vqgan.VQGANDataset
  filelist: data/vocoder_data_441/vq_val_filelist.txt
  sample_rate: ${sample_rate}
  hop_length: ${hop_length}

data:
  _target_: fish_speech.datasets.vqgan.VQGANDataModule
  train_dataset: ${train_dataset}
  val_dataset: ${val_dataset}
  num_workers: 4
  batch_size: 32
  val_batch_size: 4

# Model Configuration
model:
  _target_: fish_speech.models.vqgan.VQGAN
  sample_rate: ${sample_rate}
  hop_length: ${hop_length}
  segment_size: 32768
  mode: pretrain
  freeze_discriminator: true

  downsample:
    _target_: fish_speech.models.vqgan.modules.encoders.ConvDownSampler
    dims: ["${num_mels}", 512, 256]
    kernel_sizes: [3, 3]
    strides: [2, 2]

  mel_encoder:
    _target_: fish_speech.models.vqgan.modules.modules.WN
    hidden_channels: 256
    kernel_size: 3
    dilation_rate: 2
    n_layers: 12

  vq_encoder:
    _target_: fish_speech.models.vqgan.modules.encoders.VQEncoder
    in_channels: 256
    vq_channels: 256
    codebook_size: 256
    codebook_groups: 4
    downsample: 1

  decoder:
    _target_: fish_speech.models.vqgan.modules.modules.WN
    hidden_channels: 256
    out_channels: ${num_mels}
    kernel_size: 3
    dilation_rate: 2
    n_layers: 6

  generator:
    _target_: fish_speech.models.vqgan.modules.decoder_v2.HiFiGANGenerator
    hop_length: ${hop_length}
    upsample_rates: [8, 8, 2, 2, 2]  # aka. strides
    upsample_kernel_sizes: [16, 16, 4, 4, 4]
    resblock_kernel_sizes: [3, 7, 11]
    resblock_dilation_sizes: [[1, 3, 5], [1, 3, 5], [1, 3, 5]]
    num_mels: ${num_mels}
    upsample_initial_channel: 512
    use_template: true
    pre_conv_kernel_size: 7
    post_conv_kernel_size: 7

  discriminators:
    _target_: torch.nn.ModuleDict
    modules:
      mpd:
        _target_: fish_speech.models.vqgan.modules.discriminators.mpd.MultiPeriodDiscriminator
        periods: [2, 3, 5, 7, 11, 17, 23, 37]

      mrd:
        _target_: fish_speech.models.vqgan.modules.discriminators.mrd.MultiResolutionDiscriminator
        resolutions:
          - ["${n_fft}", "${hop_length}", "${win_length}"]
          - [1024, 120, 600]
          - [2048, 240, 1200]
          - [4096, 480, 2400]
          - [512, 50, 240]

  multi_resolution_stft_loss:
    _target_: fish_speech.models.vqgan.losses.MultiResolutionSTFTLoss
    resolutions: ${model.discriminators.modules.mrd.resolutions}
  
  mel_transform:
    _target_: fish_speech.models.vqgan.spectrogram.LogMelSpectrogram
    sample_rate: ${sample_rate}
    n_fft: ${n_fft}
    hop_length: ${hop_length}
    win_length: ${win_length}
    n_mels: ${num_mels}

  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: 1e-4
    betas: [0.8, 0.99]
    eps: 1e-5

  lr_scheduler:
    _target_: torch.optim.lr_scheduler.ExponentialLR
    _partial_: true
    gamma: 0.999999  # Estimated base on LibriTTS dataset

callbacks:
  grad_norm_monitor:
    sub_module: 
      - generator
      - discriminators
      - mel_encoder
      - vq_encoder
      - decoder
